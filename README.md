1. Built a real-time sign language translation system that converts webcam-captured hand gestures into text, improving accessibility for deaf and hard-of-hearing users.
2. Designed an end-to-end computer vision pipeline including video frame processing, hand landmark extraction, and machine learningâ€“based gesture classification.
3. Optimized the system for low-latency inference, balancing accuracy and real-time performance.
4. Implemented a modular and extensible architecture, enabling easy addition of new gestures, datasets, and sign languages.
5. Gained hands-on experience with applied machine learning, real-time computer vision, and AI system design trade-offs.
